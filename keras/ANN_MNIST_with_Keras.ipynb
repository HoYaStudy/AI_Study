{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQgYC3xDYleW"
      },
      "outputs": [],
      "source": [
        "from keras import layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH5BUesNZ3GS"
      },
      "source": [
        "# 분산 방식 Modeling - Functional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZXd0PhfYq6p"
      },
      "outputs": [],
      "source": [
        "def ANN_model_func(N_in, N_h, N_out):\n",
        "    x = layers.Input(shape=(N_in,))\n",
        "    h = layers.Activation('relu')(layers.Dense(N_h)(x))\n",
        "    y = layers.Activation('softmax')(layers.Dense(N_out)(h))\n",
        "\n",
        "    model = models.Model(x, y)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAJ68HBSh-sj"
      },
      "source": [
        "# 분산 방식 Modeling - OOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt360k0hiDBT"
      },
      "outputs": [],
      "source": [
        "class ANN_model_OOP(models.Model):\n",
        "    def __init__(self, N_in, N_h, N_out):\n",
        "        hidden = layers.Dense(N_h)\n",
        "        output = layers.Dense(N_out)\n",
        "        relu = layers.Activation('relu')\n",
        "        softmax = layers.Activation('softmax')\n",
        "\n",
        "        x = layers.Input(shape=(N_in,))\n",
        "        h = relu(hidden(x))\n",
        "        y = softmax(output(h))\n",
        "\n",
        "        super().__init__(x, y)\n",
        "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTChhv-ShI0w"
      },
      "source": [
        "# 연쇄 방식 Modeling - Functional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjrVYAsdZ7kq"
      },
      "outputs": [],
      "source": [
        "def ANN_seq_func(N_in, N_h, N_out):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(N_h, activation='relu', input_shape=(N_in,)))\n",
        "    model.add(layers.Dense(N_out, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj1yTjYRjE3f"
      },
      "source": [
        "# 연쇄 방식 Modeling - OOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnmafOFdjIGx"
      },
      "outputs": [],
      "source": [
        "class ANN_seq_OOP(models.Sequential):\n",
        "    def __init__(self, N_in, N_h, N_out):\n",
        "        super().__init__()\n",
        "        self.add(layers.Dense(N_h, activation='relu', input_shape=(N_in,)))\n",
        "        self.add(layers.Dense(N_out, activation='softmax'))\n",
        "        self.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYyAHNT3ivpX"
      },
      "source": [
        "# Data - MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqEMy900iu3u"
      },
      "outputs": [],
      "source": [
        "def data_mnist():\n",
        "    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "\n",
        "    Y_train = np_utils.to_categorical(Y_train)\n",
        "    Y_test = np_utils.to_categorical(Y_test)\n",
        "\n",
        "    L, H, W = X_train.shape\n",
        "    X_train = X_train.reshape(-1, H * W)\n",
        "    X_test = X_test.reshape(-1, H * W)\n",
        "\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "\n",
        "    return (X_train, Y_train), (X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSSAqJg3kpSY"
      },
      "source": [
        "# Draw Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdnfV6vUkq7h"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history, title=None):\n",
        "    if not isinstance(history, dict):\n",
        "        history = history.history\n",
        "\n",
        "    plt.plot(history['loss'])\n",
        "    plt.plot(history['val_loss'])\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training', 'Validation'], loc=0)\n",
        "\n",
        "def plot_acc(history, title=None):\n",
        "    if not isinstance(history, dict):\n",
        "        history = history.history\n",
        "\n",
        "    plt.plot(history['accuracy'])\n",
        "    plt.plot(history['val_accuracy'])\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Training', 'Validation'], loc=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJMDwQ8liws"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gu08PCjljw7"
      },
      "outputs": [],
      "source": [
        "NUMBER_OF_CLASS = 10\n",
        "\n",
        "N_in = 784\n",
        "N_h = 100\n",
        "N_out = NUMBER_OF_CLASS\n",
        "\n",
        "model = ANN_model_func(N_in, N_h, N_out)\n",
        "# model = ANN_model_OOP(N_in, N_h, N_out)\n",
        "# model = ANN_seq_func(N_in, N_h, N_out)\n",
        "# model = ANN_seq_OOP(N_in, N_h, N_out)\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = data_mnist()\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=5, batch_size=100, validation_split=0.2)\n",
        "\n",
        "performance = model.evaluate(X_test, Y_test, batch_size=100)\n",
        "print(f\"Test Loss and Accuracy -> {performance}\")\n",
        "\n",
        "plot_loss(history)\n",
        "plt.show()\n",
        "plot_acc(history)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ANN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "27640c38ce2adddea55846e439bfdf3cf133fd1f7141848aed330a8836e8eaec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
