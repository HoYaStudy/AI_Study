{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQgYC3xDYleW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from keras import backend, models, layers, optimizers\n",
        "from keras.datasets import mnist\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj1yTjYRjE3f"
      },
      "source": [
        "# 연쇄 방식 Modeling - OOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnmafOFdjIGx"
      },
      "outputs": [],
      "source": [
        "def mse_4d(y_true, y_pred):\n",
        "    return backend.mean(backend.square(y_pred - y_true), axis=(1, 2, 3))\n",
        "    \n",
        "def mse_4d_tf(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_pred - y_true), axis=(1, 2, 3))\n",
        "\n",
        "class GAN_Seq_OOP(models.Sequential):\n",
        "    def __init__(self, input_dim=64):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.generator = self._generator()\n",
        "        self.discriminator = self._discriminator()\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        self.add(self.generator)\n",
        "        self.add(self.discriminator)\n",
        "        self.compile_all()\n",
        "\n",
        "    def compile_all(self):\n",
        "        d_optim = optimizers.SGD(learning_rate=0.0005, momentum=0.9, nesterov=True)\n",
        "        g_optim = optimizers.SGD(learning_rate=0.0005, momentum=0.9, nesterov=True)\n",
        "\n",
        "        self.generator.compile(loss=mse_4d_tf, optimizer=\"SGD\")\n",
        "        self.compile(loss='binary_crossentropy', optimizer=g_optim)\n",
        "        self.discriminator.trainable = True\n",
        "        self.discriminator.compile(loss='binary_crossentropy', optimizer=d_optim)\n",
        "\n",
        "    def _generator(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Dense(1024, activation='tanh', input_dim=self.input_dim))\n",
        "        model.add(layers.Dense(7 * 7* 128, activation='tanh'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Reshape((7, 7, 128), input_shape=(7 * 7 * 128,)))\n",
        "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh'))\n",
        "        model.add(layers.UpSampling2D(size=(2, 2)))\n",
        "        model.add(layers.Conv2D(1, (5, 5), padding='same', activation='tanh'))\n",
        "        return model\n",
        "\n",
        "    def _discriminator(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(64, (5, 5), padding='same', activation='tanh', input_shape=(28, 28, 1)))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation='tanh'))\n",
        "        model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(1024, activation='tanh'))\n",
        "        model.add(layers.Dense(1, activation='sigmoid'))\n",
        "        return model\n",
        "\n",
        "    def get_z(self, ln):\n",
        "        return np.random.uniform(-1, 1, (ln, self.input_dim))\n",
        "\n",
        "    def train_both(self, x):\n",
        "        ln = x.shape[0]\n",
        "        z = self.get_z(ln)\n",
        "        w = self.generator.predict(z, verbose=0)\n",
        "        xw = np.concatenate((x, w))\n",
        "        y2 = np.array([1] * ln + [0] * ln).reshape(-1, 1)\n",
        "        d_loss = self.discriminator.train_on_batch(xw, y2)\n",
        "\n",
        "        z = self.get_z(ln)\n",
        "        self.discriminator.trainable = False\n",
        "        g_loss = self.train_on_batch(z, np.array([1] * ln).reshape(-1, 1))\n",
        "        self.discriminator.trainable = True\n",
        "\n",
        "        return d_loss, g_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def combine_images(generated_images):\n",
        "    num = generated_images.shape[0]\n",
        "    width = int(math.sqrt(num))\n",
        "    height = int(math.ceil(float(num) / width))\n",
        "    shape = generated_images.shape[1:3]\n",
        "    image = np.zeros((height * shape[0], width * shape[1]), dtype=generated_images.dtype)\n",
        "    for index, img in enumerate(generated_images):\n",
        "        i = int(index / width)\n",
        "        j = index % width\n",
        "        image[i * shape[0]:(i + 1) * shape[0], j * shape[1]:(j + 1) * shape[1]] = img[:, :, 0]\n",
        "    return image\n",
        "\n",
        "def get_x(x_train, index, batch_size):\n",
        "    return x_train[index * batch_size:(index + 1) * batch_size]\n",
        "\n",
        "def save_images(generated_images, output_fold, epoch, index):\n",
        "    image = combine_images(generated_images)\n",
        "    image = image * 127.5 + 127.5\n",
        "    Image.fromarray(image.astype(np.uint8)).save(output_fold + '/' + str(epoch) + \"_\" + str(index) + \".png\")\n",
        "\n",
        "def load_data(n_train):\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\n",
        "    return x_train[:n_train]\n",
        "\n",
        "def train(args):\n",
        "    batch_size = args.batch_size\n",
        "    epochs = args.epochs\n",
        "    output_fold = args.output_fold\n",
        "    input_dim = args.input_dim\n",
        "    n_train = args.n_train\n",
        "\n",
        "    os.makedirs(output_fold, exist_ok=True)\n",
        "\n",
        "    x_train = load_data(n_train)\n",
        "    x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
        "    x_train = x_train.reshape(x_train.shape + (1,))\n",
        "\n",
        "    gan = GAN_Seq_OOP(input_dim)\n",
        "\n",
        "    d_loss_ll = []\n",
        "    g_loss_ll = []\n",
        "    for epoch in range(epochs):\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch is {epoch}')\n",
        "            print(f'Number of batches {int(x_train.shape[0] / batch_size)}')\n",
        "        \n",
        "        d_loss_l = []\n",
        "        g_loss_l = []\n",
        "        for index in range(int(x_train.shape[0] / batch_size)):\n",
        "            x = get_x(x_train, index, batch_size)\n",
        "            d_loss, g_loss = gan.train_both(x)\n",
        "            d_loss_l.append(d_loss)\n",
        "            g_loss_l.append(g_loss)\n",
        "        if epoch % 10 == 0 or epoch == epochs - 1:\n",
        "            z = gan.get_z(x.shape[0])\n",
        "            w = gan.generator.predict(z, verbose=0)\n",
        "            save_images(w, output_fold, epoch, 0)\n",
        "        d_loss_ll.append(d_loss_l)\n",
        "        g_loss_ll.append(g_loss_l)\n",
        "    \n",
        "    gan.generator.save_weights(output_fold + '/' + 'generator', True)\n",
        "    gan.discriminator.save_weights(output_fold + '/' + 'discriminator', True)\n",
        "\n",
        "    np.savetxt(output_fold + '/' + 'd_loss', d_loss_ll)\n",
        "    np.savetxt(output_fold + '/' + 'g_loss', g_loss_ll)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJMDwQ8liws"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gu08PCjljw7"
      },
      "outputs": [],
      "source": [
        "class ARGS:\n",
        "    def __init__(args):\n",
        "        args.batch_size = 16\n",
        "        args.epochs = 1000\n",
        "        args.output_fold = 'GAN_OUT'\n",
        "        args.input_dim = 10\n",
        "        args.n_train = 32\n",
        "\n",
        "args = ARGS()\n",
        "train(args)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ANN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "27640c38ce2adddea55846e439bfdf3cf133fd1f7141848aed330a8836e8eaec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
