{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQgYC3xDYleW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import uuid\n",
        "import keras\n",
        "from keras import backend\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.utils import np_utils\n",
        "from sklearn import model_selection, metrics\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Utility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def unique_filename(type='uuid'):\n",
        "    if type == 'datetime':\n",
        "        filename = datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "    else:\n",
        "        filename = str(uuid.uuid4())\n",
        "    return filename\n",
        "\n",
        "def makenewfold(prefix='output_', type='datetime'):\n",
        "    suffix = unique_filename('datetime')\n",
        "    foldname = 'output_' + suffix\n",
        "    os.makedirs(foldname)\n",
        "    return foldname\n",
        "\n",
        "def save_history_history(fname, history_history, fold=''):\n",
        "    np.save(os.path.join(fold, fname), history_history)\n",
        "\n",
        "def load_history_history(fname, fold=''):\n",
        "    history_history = np.load(os.path.join(fold, fname)).item(0)\n",
        "    return history_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj1yTjYRjE3f"
      },
      "source": [
        "# 분산 방식 Modeling - OOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnmafOFdjIGx"
      },
      "outputs": [],
      "source": [
        "class CNN_Model_OOP(Model):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNN_Model_OOP, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv2D_1 = Conv2D(32, kernel_size=(3, 3), activation='relu')\n",
        "        self.conv2D_2 = Conv2D(64, kernel_size=(3, 3), activation='relu')\n",
        "        self.maxPooling2D = MaxPooling2D(pool_size=(2, 2))\n",
        "        self.dropout_1 = Dropout(0.25)\n",
        "        self.dropout_2 = Dropout(0.5)\n",
        "        self.flatten = Flatten()\n",
        "        self.dense_1 = Dense(128, activation='relu')\n",
        "        self.dense_2 = Dense(num_classes, activation='softmax', name='pred')\n",
        "\n",
        "    def call(self, x):\n",
        "        h = self.conv2D_1(x)\n",
        "        h = self.conv2D_2(h)\n",
        "        h = self.maxPooling2D(h)\n",
        "        h = self.dropout_1(h)\n",
        "        h = self.flatten(h)\n",
        "\n",
        "        h = self.dense_1(h)\n",
        "        h = self.dropout_2(h)\n",
        "\n",
        "        y = self.dense_2(h)\n",
        "\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYyAHNT3ivpX"
      },
      "source": [
        "# Data - CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqEMy900iu3u"
      },
      "outputs": [],
      "source": [
        "class Data_CIFAR10():\n",
        "    def __init__(self, x, y, num_classes, scaling=True, test_size=0.2, random_state=0):\n",
        "        self.x = x\n",
        "        self.add_channels()\n",
        "        x = self.x\n",
        "\n",
        "        x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.2, random_state=random_state)\n",
        "        x_train = x_train.astype('float32')\n",
        "        x_test = x_test.astype('float32')\n",
        "\n",
        "        if scaling:\n",
        "            scaler = MinMaxScaler()\n",
        "            n = x_train.shape[0]\n",
        "            x_train = scaler.fit_transform(x_train.reshape(n, -1)).reshape(x_train.shape)\n",
        "            n = x_test.shape[0]\n",
        "            x_test = scaler.transform(x_test.reshape(n, -1)).reshape(x_test.shape)\n",
        "            self.scaler = scaler\n",
        "\n",
        "        y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "        y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "        \n",
        "        self.x_train, self.x_test = x_train, x_test\n",
        "        self.y_train, self.y_test = y_train, y_test\n",
        "\n",
        "    def add_channels(self):\n",
        "        x = self.x\n",
        "\n",
        "        if len(x.shape) == 3:\n",
        "            n, img_rows, img_cols = x.shape\n",
        "\n",
        "            if backend.image_dim_ordering() == 'th':\n",
        "                x = x.reshape(x.shape[0], 1, img_rows, img_cols)\n",
        "                input_shape = (1, img_rows, img_cols)\n",
        "            else:\n",
        "                x = x.reshape(x.shape[0], img_rows, img_cols, 1)\n",
        "                input_shape = (img_rows, img_cols, 1)\n",
        "        else:\n",
        "            input_shape = x.shape[1:]\n",
        "\n",
        "        self.x = x\n",
        "        self.input_shape = input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Machine():\n",
        "    def __init__(self, x, y, num_classes=2, fig=True):\n",
        "        self.num_classes = num_classes\n",
        "        self.set_data(x, y)\n",
        "        self.set_model()\n",
        "        self.fig = fig\n",
        "\n",
        "    def set_data(self, x, y):\n",
        "        self.data = Data_CIFAR10(x, y, self.num_classes)\n",
        "\n",
        "    def set_model(self):\n",
        "        self.model = CNN_Model_OOP(num_classes=self.num_classes)\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "    def fit(self, epochs=10, batch_size=128, verbose=1):\n",
        "        history = self.model.fit(self.data.x_train, self.data.y_train, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(self.data.x_test, self.data.y_test))\n",
        "        return history\n",
        "\n",
        "    def run(self, epochs=100, batch_size=128, verbose=1):\n",
        "        history = self.fit(epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "        score = self.model.evaluate(self.data.x_test, self.data.y_test, verbose=0)\n",
        "\n",
        "        y_test_pred = self.model.predict(self.data.x_test, verbose=0)\n",
        "        y_test_pred = np.argmax(y_test_pred, axis=1)\n",
        "        print(metrics.confusion_matrix(self.data.y_test, y_test_pred))\n",
        "        print(f'Test score: {score[0]}')\n",
        "        print(f'Test accuracy: {score[1]}')\n",
        "\n",
        "        suffix = unique_filename('datetime')\n",
        "        foldname = 'output_' + suffix\n",
        "        os.makedirs(foldname)\n",
        "        save_history_history('history.npy', history.history, fold=foldname)\n",
        "        self.model.save_weights(os.path.join(foldname, 'lenet_model.h5'))\n",
        "\n",
        "        if self.fig:\n",
        "            plt.figure(figsize=(12, 4))\n",
        "            plt.subplot(1, 2, 1)\n",
        "            self.plot_acc(history)\n",
        "            plt.subplot(1, 2, 2)\n",
        "            self.plot_loss(history)\n",
        "            plt.show()\n",
        "\n",
        "    def plot_loss(self, history, title=None):\n",
        "        if not isinstance(history, dict):\n",
        "            history = history.history\n",
        "\n",
        "        plt.plot(history['loss'])\n",
        "        plt.plot(history['val_loss'])\n",
        "        if title is not None:\n",
        "            plt.title(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend(['Training', 'Validation'], loc=0)\n",
        "\n",
        "    def plot_acc(self, history, title=None):\n",
        "        if not isinstance(history, dict):\n",
        "            history = history.history\n",
        "\n",
        "        plt.plot(history['accuracy'])\n",
        "        plt.plot(history['val_accuracy'])\n",
        "        if title is not None:\n",
        "            plt.title(title)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend(['Training', 'Validation'], loc=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rJMDwQ8liws"
      },
      "source": [
        "# Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Gu08PCjljw7"
      },
      "outputs": [],
      "source": [
        "class LeNetMachine(Machine):\n",
        "    def __init__(self):\n",
        "        (x, y), (x_test, y_test) = cifar10.load_data()\n",
        "        super().__init__(x, y, num_classes=10)\n",
        "\n",
        "le_net = LeNetMachine()\n",
        "le_net.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ANN.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "27640c38ce2adddea55846e439bfdf3cf133fd1f7141848aed330a8836e8eaec"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
